import os
import re
import json
import httpx
from datetime import datetime
from google import genai
from google.genai import types
from .db import save_news


GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY", "")

SYSTEM_INSTRUCTION = """ë„ˆëŠ” ë‰´ìŠ¤ ìš”ì•½ ë´‡ì´ë‹¤.
ì ˆëŒ€ ê·œì¹™:
- ì¸ì‚¬ë§ ê¸ˆì§€ (ì•Œê² ìŠµë‹ˆë‹¤, ì œê³µí•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤, ì£„ì†¡í•©ë‹ˆë‹¤ ë“±)
- ì„œë¡ /ë¶€ì—° ì„¤ëª… ê¸ˆì§€
- ì²« ì¤„ë¶€í„° ë°”ë¡œ "1. **ì œëª©**" ìœ¼ë¡œ ì‹œì‘
- ì§€ì •ëœ í˜•ì‹ë§Œ ì¶œë ¥
- í•œêµ­ì–´ë¡œ ì‘ì„±
- ì¶œì²˜ URLì€ ë°˜ë“œì‹œ ì‹¤ì œ ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì›ë³¸ URLì„ í¬í•¨ (ë¦¬ë‹¤ì´ë ‰íŠ¸ URL ê¸ˆì§€)
- ì›ë¬¸ í‘œí˜„ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì§€ ë§ê³ , íŒ©íŠ¸ë§Œ ê°„ê²°í•˜ê²Œ ì „ë‹¬"""

PROMPTS = {
    "us": {
        "general": "ì˜¤ëŠ˜ì˜ ë¯¸êµ­ ì£¼ìš” ë‰´ìŠ¤(ì •ì¹˜, ì‚¬íšŒ, êµ­ì œ ë“±) 5ê°œë¥¼ ê²€ìƒ‰í•´ì„œ ì•„ë˜ í˜•ì‹ ê·¸ëŒ€ë¡œ ì¶œë ¥í•´.",
        "tech": """ì˜¤ëŠ˜ì˜ ë¯¸êµ­ IT/í…Œí¬/ê¸°ìˆ  ë¶„ì•¼ ë‰´ìŠ¤ë§Œ 5ê°œë¥¼ ê²€ìƒ‰í•´ì„œ ì•„ë˜ í˜•ì‹ ê·¸ëŒ€ë¡œ ì¶œë ¥í•´.
ë°˜ë“œì‹œ ê¸°ìˆ  ê´€ë ¨ ë‰´ìŠ¤ë§Œ í¬í•¨í•  ê²ƒ: AI, ì†Œí”„íŠ¸ì›¨ì–´, í•˜ë“œì›¨ì–´, ë°˜ë„ì²´, ìŠ¤íƒ€íŠ¸ì—…, ë¹…í…Œí¬(Apple, Google, Microsoft, Meta, Amazon, Tesla ë“±), ì‚¬ì´ë²„ë³´ì•ˆ, í´ë¼ìš°ë“œ ë“±.
ì •ì¹˜/ê²½ì œ/ì—°ì˜ˆ ë‰´ìŠ¤ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆ.""",
        "economy": """ì˜¤ëŠ˜ì˜ ë¯¸êµ­ ê²½ì œ/ê¸ˆìœµ ë¶„ì•¼ ë‰´ìŠ¤ë§Œ 5ê°œë¥¼ ê²€ìƒ‰í•´ì„œ ì•„ë˜ í˜•ì‹ ê·¸ëŒ€ë¡œ ì¶œë ¥í•´.
ë°˜ë“œì‹œ ê²½ì œ ê´€ë ¨ ë‰´ìŠ¤ë§Œ í¬í•¨í•  ê²ƒ: ì£¼ì‹ì‹œì¥, ì—°ì¤€(Fed), ê¸ˆë¦¬, í™˜ìœ¨, GDP, ê³ ìš©ì§€í‘œ, ê¸°ì—…ì‹¤ì , ë¶€ë™ì‚°, ë¬´ì—­, ê´€ì„¸ ë“±.
ì •ì¹˜/í…Œí¬/ì—°ì˜ˆ ë‰´ìŠ¤ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆ.""",
        "entertainment": """ì˜¤ëŠ˜ì˜ ë¯¸êµ­ ì—°ì˜ˆ/ë¬¸í™”/ìŠ¤í¬ì¸  ë¶„ì•¼ ë‰´ìŠ¤ë§Œ 5ê°œë¥¼ ê²€ìƒ‰í•´ì„œ ì•„ë˜ í˜•ì‹ ê·¸ëŒ€ë¡œ ì¶œë ¥í•´.
ë°˜ë“œì‹œ ì—”í„°í…Œì¸ë¨¼íŠ¸ ê´€ë ¨ ë‰´ìŠ¤ë§Œ í¬í•¨í•  ê²ƒ: í• ë¦¬ìš°ë“œ, ì˜í™”, ìŒì•…, TV, ìŠ¤í¬ì¸ (NFL, NBA, MLB ë“±), ì…€ëŸ½, ì‹œìƒì‹ ë“±.
ì •ì¹˜/ê²½ì œ/í…Œí¬ ë‰´ìŠ¤ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆ.""",
    },
    "kr": {
        "general": "ì˜¤ëŠ˜ì˜ í•œêµ­ ì£¼ìš” ë‰´ìŠ¤(ì •ì¹˜, ì‚¬íšŒ, êµ­ì œ ë“±) 5ê°œë¥¼ ê²€ìƒ‰í•´ì„œ ì•„ë˜ í˜•ì‹ ê·¸ëŒ€ë¡œ ì¶œë ¥í•´.",
        "tech": """ì˜¤ëŠ˜ì˜ í•œêµ­ IT/í…Œí¬/ê¸°ìˆ  ë¶„ì•¼ ë‰´ìŠ¤ë§Œ 5ê°œë¥¼ ê²€ìƒ‰í•´ì„œ ì•„ë˜ í˜•ì‹ ê·¸ëŒ€ë¡œ ì¶œë ¥í•´.
ë°˜ë“œì‹œ ê¸°ìˆ  ê´€ë ¨ ë‰´ìŠ¤ë§Œ í¬í•¨í•  ê²ƒ: AI, ë°˜ë„ì²´, ì‚¼ì„±ì „ì, SKí•˜ì´ë‹‰ìŠ¤, ë„¤ì´ë²„, ì¹´ì¹´ì˜¤, ìŠ¤íƒ€íŠ¸ì—…, í†µì‹ ì‚¬, ê²Œì„ ë“±.
ì •ì¹˜/ê²½ì œ/ì—°ì˜ˆ ë‰´ìŠ¤ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆ.""",
        "economy": """ì˜¤ëŠ˜ì˜ í•œêµ­ ê²½ì œ/ê¸ˆìœµ ë¶„ì•¼ ë‰´ìŠ¤ë§Œ 5ê°œë¥¼ ê²€ìƒ‰í•´ì„œ ì•„ë˜ í˜•ì‹ ê·¸ëŒ€ë¡œ ì¶œë ¥í•´.
ë°˜ë“œì‹œ ê²½ì œ ê´€ë ¨ ë‰´ìŠ¤ë§Œ í¬í•¨í•  ê²ƒ: ì½”ìŠ¤í”¼, ì½”ìŠ¤ë‹¥, í•œêµ­ì€í–‰, ê¸ˆë¦¬, í™˜ìœ¨, ë¶€ë™ì‚°, ê¸°ì—…ì‹¤ì , ìˆ˜ì¶œì…, ë¬¼ê°€ ë“±.
ì •ì¹˜/í…Œí¬/ì—°ì˜ˆ ë‰´ìŠ¤ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆ.""",
        "entertainment": """ì˜¤ëŠ˜ì˜ í•œêµ­ ì—°ì˜ˆ/ë¬¸í™”/ìŠ¤í¬ì¸  ë¶„ì•¼ ë‰´ìŠ¤ë§Œ 5ê°œë¥¼ ê²€ìƒ‰í•´ì„œ ì•„ë˜ í˜•ì‹ ê·¸ëŒ€ë¡œ ì¶œë ¥í•´.
ë°˜ë“œì‹œ ì—”í„°í…Œì¸ë¨¼íŠ¸ ê´€ë ¨ ë‰´ìŠ¤ë§Œ í¬í•¨í•  ê²ƒ: K-pop, ë“œë¼ë§ˆ, ì˜í™”, ì•„ì´ëŒ, ì˜ˆëŠ¥, KBO, Kë¦¬ê·¸, ì…€ëŸ½ ë“±.
ì •ì¹˜/ê²½ì œ/í…Œí¬ ë‰´ìŠ¤ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆ.""",
    }
}

FORMAT_INSTRUCTION = """
ê° ë‰´ìŠ¤ì˜ ì‹¤ì œ ì›ë³¸ ê¸°ì‚¬ URLì„ ë°˜ë“œì‹œ í¬í•¨í•´.

1. **ì œëª©**
ìš”ì•½ 1~2ë¬¸ì¥ (ìµœëŒ€ 80ì)
ì¶œì²˜: ë§¤ì²´ëª… (https://ì‹¤ì œê¸°ì‚¬URL)

... (ë°˜ë³µ) ...

ğŸ“Œ ì‹œì‚¬ì : 1~2ë¬¸ì¥
"""


def clean_summary(raw: str) -> str:
    match = re.search(r'1\.\s*\*\*', raw)
    if match:
        return raw[match.start():]
    return raw


def parse_sources_json(text: str) -> str:
    sources = []
    pattern = re.compile(r'ì¶œì²˜:\s*(.+?)\s*\((https?://[^\s\)]+)\)')
    for m in pattern.finditer(text):
        sources.append({"title": m.group(1).strip(), "link": m.group(2).strip()})
    return json.dumps(sources, ensure_ascii=False)


def resolve_redirect(url: str) -> str:
    """Google ë¦¬ë‹¤ì´ë ‰íŠ¸ URLì„ ì‹¤ì œ URLë¡œ í•´ì†Œ"""
    google_domains = ["google.com/url", "vertexaisearch.cloud.google.com", "news.google.com"]
    if not any(domain in url for domain in google_domains):
        return url
    try:
        with httpx.Client(follow_redirects=True, timeout=10.0) as c:
            resp = c.head(url)
            return str(resp.url)
    except Exception:
        return url


def validate_url(url: str) -> bool:
    """HTTP HEAD ìš”ì²­ìœ¼ë¡œ URL ì¡´ì¬ ì—¬ë¶€ ê²€ì¦"""
    try:
        with httpx.Client(follow_redirects=True, timeout=10.0) as c:
            resp = c.head(url)
            return resp.status_code < 400
    except Exception:
        return False


def fetch_and_store(region: str, category: str = "general"):
    """Geminië¡œ ë‰´ìŠ¤ ìš”ì•½ì„ ìƒì„±í•˜ê³  DBì— ì €ì¥"""
    print(f"[{datetime.now()}] {region} [{category}] ë‰´ìŠ¤ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")

    prompt = PROMPTS[region][category] + FORMAT_INSTRUCTION

    client = genai.Client(api_key=GEMINI_API_KEY)
    response = client.models.generate_content(
        model="gemini-2.0-flash",
        contents=prompt,
        config=types.GenerateContentConfig(
            tools=[types.Tool(google_search=types.GoogleSearch())],
            system_instruction=SYSTEM_INSTRUCTION,
        ),
    )
    raw = response.text or ""
    summary = clean_summary(raw)

    # ë¦¬ë‹¤ì´ë ‰íŠ¸ URL í•´ì†Œ ë° ê²€ì¦
    url_pattern = re.compile(r'\((https?://[^\s\)]+)\)')
    urls = url_pattern.findall(summary)
    for url in urls:
        real_url = resolve_redirect(url)
        if real_url != url:
            summary = summary.replace(url, real_url)
            url = real_url
        # URL ì¡´ì¬ ì—¬ë¶€ ê²€ì¦ â€” ê¹¨ì§„ URLì€ ì œê±°í•˜ê³  ì¶œì²˜ í…ìŠ¤íŠ¸ë§Œ ë‚¨ê¹€
        if not validate_url(url):
            summary = summary.replace(f" ({url})", "")
            summary = summary.replace(f"({url})", "")

    sources = parse_sources_json(summary)
    save_news(region, category, summary, sources)
    print(f"[{datetime.now()}] {region} [{category}] ë‰´ìŠ¤ ì €ì¥ ì™„ë£Œ")
